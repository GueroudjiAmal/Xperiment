distributed.scheduler - INFO - -----------------------------------------------
distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
distributed.scheduler - INFO - -----------------------------------------------
distributed.scheduler - INFO - Clear task state
distributed.scheduler - INFO -   Scheduler at:   tcp://172.21.2.189:8786
distributed.scheduler - INFO -   dashboard at:                     :8787
distributed.scheduler - INFO - Receive client connection: Client-06aa6997-8789-11ed-9ff7-080038b543e2
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aa7325-8789-11ed-9ff8-080038b543e2
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aaf0af-8789-11ed-b78a-080038b56098
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aaf9c2-8789-11ed-8e18-080038b540d1
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aaff2e-8789-11ed-8e17-080038b540d1
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aad754-8789-11ed-8e1a-080038b54392
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aaf933-8789-11ed-b78b-080038b56098
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aacd4d-8789-11ed-8e1b-080038b54392
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aabede-8789-11ed-95e5-080038b51320
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aac557-8789-11ed-95e6-080038b51320
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aac56e-8789-11ed-a017-080038b5487e
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aae255-8789-11ed-9923-080038b5129e
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aad001-8789-11ed-a018-080038b5487e
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aa6cbc-8789-11ed-b8d3-080038b6198d
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aa7131-8789-11ed-b8d4-080038b6198d
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06ab32af-8789-11ed-b096-080038b54234
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aae95b-8789-11ed-9513-080038b56cc8
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aae3c6-8789-11ed-9514-080038b56cc8
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aa848b-8789-11ed-a41b-080038b5132a
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aa8070-8789-11ed-a41c-080038b5132a
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06ad5cf8-8789-11ed-ba31-080038b5460d
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06ab27eb-8789-11ed-b095-080038b54234
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aae6e1-8789-11ed-9924-080038b5129e
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aadc3c-8789-11ed-ab1a-080038b5435b
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06ab31cf-8789-11ed-9b3a-080038b54617
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aae102-8789-11ed-ab1b-080038b5435b
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06ab2d6f-8789-11ed-9b39-080038b54617
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aabbd9-8789-11ed-bfdc-080038b5413a
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aad234-8789-11ed-b813-080038b54f72
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aae008-8789-11ed-b814-080038b54f72
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aacb00-8789-11ed-bc65-080038b541e9
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aac264-8789-11ed-bc64-080038b541e9
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-06aab3ac-8789-11ed-bfdb-080038b5413a
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.4.180:34007', name: tcp://172.21.4.180:34007, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.4.180:34007
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.4.180:45980', name: tcp://172.21.4.180:45980, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.4.180:45980
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.4.184:33453', name: tcp://172.21.4.184:33453, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.4.184:33453
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.4.184:45721', name: tcp://172.21.4.184:45721, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.4.184:45721
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.4.183:41342', name: tcp://172.21.4.183:41342, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.4.183:41342
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.4.183:39334', name: tcp://172.21.4.183:39334, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.4.183:39334
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.2.192:37691', name: tcp://172.21.2.192:37691, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.2.192:37691
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.2.192:46753', name: tcp://172.21.2.192:46753, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.2.192:46753
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.2.194:44438', name: tcp://172.21.2.194:44438, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.2.194:44438
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.2.194:36787', name: tcp://172.21.2.194:36787, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.2.194:36787
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.2.193:35024', name: tcp://172.21.2.193:35024, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.2.193:35024
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.2.191:43019', name: tcp://172.21.2.191:43019, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.2.191:43019
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.2.191:46210', name: tcp://172.21.2.191:46210, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.2.191:46210
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.4.182:38593', name: tcp://172.21.4.182:38593, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.4.182:38593
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.2.193:40792', name: tcp://172.21.2.193:40792, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.2.193:40792
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.21.4.182:40148', name: tcp://172.21.4.182:40148, status: undefined, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://172.21.4.182:40148
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Run out-of-band function 'lambda'
distributed.scheduler - INFO - Scheduler closing...
distributed.scheduler - INFO - Clear task state
tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x2b4e2a13a550>, <Task finished name='Task-1815' coro=<BaseTCPListener._handle_stream() done, defined at /ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/tcp.py:502> exception=OSError(98, 'Address already in use')>)
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/tornado/tcpserver.py", line 331, in <lambda>
    gen.convert_yielded(future), lambda f: f.result()
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/tcp.py", line 519, in _handle_stream
    await self.comm_handler(comm)
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 449, in handle_comm
    await self
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 275, in _
    await self.start()
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/scheduler.py", line 3988, in start
    await self.listen(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 421, in listen
    listener = await listen(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/core.py", line 207, in _
    await self.start()
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/tcp.py", line 477, in start
    sockets = netutil.bind_sockets(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/tornado/netutil.py", line 161, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.2.193:40792', name: tcp://172.21.2.193:40792, status: closing, memory: 0, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.2.193:40792
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.2.191:46210', name: tcp://172.21.2.191:46210, status: closing, memory: 1, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.2.191:46210
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.2.192:46753', name: tcp://172.21.2.192:46753, status: closing, memory: 0, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.2.192:46753
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.4.182:38593', name: tcp://172.21.4.182:38593, status: closing, memory: 0, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.4.182:38593
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.2.194:44438', name: tcp://172.21.2.194:44438, status: closing, memory: 0, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.2.194:44438
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.2.192:37691', name: tcp://172.21.2.192:37691, status: closing, memory: 2, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.2.192:37691
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.4.182:40148', name: tcp://172.21.4.182:40148, status: closing, memory: 0, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.4.182:40148
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.2.194:36787', name: tcp://172.21.2.194:36787, status: closing, memory: 0, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.2.194:36787
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.2.191:43019', name: tcp://172.21.2.191:43019, status: closing, memory: 0, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.2.191:43019
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.4.180:45980', name: tcp://172.21.4.180:45980, status: closing, memory: 0, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.4.180:45980
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.4.184:33453', name: tcp://172.21.4.184:33453, status: closing, memory: 0, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.4.184:33453
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.4.184:45721', name: tcp://172.21.4.184:45721, status: closing, memory: 0, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.4.184:45721
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.4.183:41342', name: tcp://172.21.4.183:41342, status: closing, memory: 0, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.4.183:41342
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.4.183:39334', name: tcp://172.21.4.183:39334, status: closing, memory: 0, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.4.183:39334
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.4.180:34007', name: tcp://172.21.4.180:34007, status: closing, memory: 0, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.4.180:34007
distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://172.21.2.193:35024', name: tcp://172.21.2.193:35024, status: closing, memory: 0, processing: 0>
distributed.core - INFO - Removing comms to tcp://172.21.2.193:35024
distributed.scheduler - INFO - Lost all workers
distributed.scheduler - INFO - Scheduler closing all comms
distributed.scheduler - INFO - End scheduler at 'tcp://172.21.2.189:8786'
