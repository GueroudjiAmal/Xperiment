distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.213:45241'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.213:34592'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.212:37283'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.211:43103'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.210:36097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.212:40589'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.178:40918'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.178:38333'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.239:39444'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.239:43613'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.171:39359'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.171:36583'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.193:40259'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.193:36923'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.172:46754'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.172:32898'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.201:44474'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.201:38866'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.211:46536'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.210:38972'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.216:45340'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.192:39719'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.192:36373'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.216:42938'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.252:35005'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.180:37808'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.180:37128'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.252:32921'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.233:33572'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.233:44085'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.214:38689'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.214:44444'
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.212:38490
distributed.worker - INFO -          Listening to:   tcp://172.21.2.212:38490
distributed.worker - INFO -          dashboard at:         172.21.2.212:44393
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-a93if9im
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.212:46110
distributed.worker - INFO -          Listening to:   tcp://172.21.2.212:46110
distributed.worker - INFO -          dashboard at:         172.21.2.212:41105
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1njzx6wn
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.213:41273
distributed.worker - INFO -          Listening to:   tcp://172.21.2.213:41273
distributed.worker - INFO -          dashboard at:         172.21.2.213:41627
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.213:42503
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO -          Listening to:   tcp://172.21.2.213:42503
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          dashboard at:         172.21.2.213:46287
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-bu62gghk
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-jd3_zi_x
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.193:35830
distributed.worker - INFO -          Listening to:   tcp://172.21.2.193:35830
distributed.worker - INFO -          dashboard at:         172.21.2.193:35322
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5kttt6oa
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.239:35949
distributed.worker - INFO -          Listening to:   tcp://172.21.2.239:35949
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.239:40928
distributed.worker - INFO -          dashboard at:         172.21.2.239:34994
distributed.worker - INFO -          Listening to:   tcp://172.21.2.239:40928
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO -          dashboard at:         172.21.2.239:35492
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.210:36437
distributed.worker - INFO -          Listening to:   tcp://172.21.2.210:36437
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.210:33593
distributed.worker - INFO -          Listening to:   tcp://172.21.2.210:33593
distributed.worker - INFO -          dashboard at:         172.21.2.210:35147
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -          dashboard at:         172.21.2.210:33846
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.193:45551
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO -          Listening to:   tcp://172.21.2.193:45551
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-a45zu37n
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO -          dashboard at:         172.21.2.193:35584
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-f1rb9mx6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qfe2idmn
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5ih8qsjm
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6ef1q4b2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.178:42035
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.178:44423
distributed.worker - INFO -          Listening to:   tcp://172.21.2.178:44423
distributed.worker - INFO -          Listening to:   tcp://172.21.2.178:42035
distributed.worker - INFO -          dashboard at:         172.21.2.178:40408
distributed.worker - INFO -          dashboard at:         172.21.2.178:41760
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-rn8wsbwh
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-c9iao102
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.211:46661
distributed.worker - INFO -          Listening to:   tcp://172.21.2.211:46661
distributed.worker - INFO -          dashboard at:         172.21.2.211:38054
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.211:46026
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://172.21.2.211:46026
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          dashboard at:         172.21.2.211:38287
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ys2lrl7l
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-l7osm_5l
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.171:39868
distributed.worker - INFO -          Listening to:   tcp://172.21.2.171:39868
distributed.worker - INFO -          dashboard at:         172.21.2.171:41502
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.171:39372
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          Listening to:   tcp://172.21.2.171:39372
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-c32rl3yg
distributed.worker - INFO -          dashboard at:         172.21.2.171:42543
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4rk01_5t
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.172:36181
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.172:42279
distributed.worker - INFO -          Listening to:   tcp://172.21.2.172:36181
distributed.worker - INFO -          Listening to:   tcp://172.21.2.172:42279
distributed.worker - INFO -          dashboard at:         172.21.2.172:36326
distributed.worker - INFO -          dashboard at:         172.21.2.172:33972
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-rv0prg4l
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-my9t3m31
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.201:43160
distributed.worker - INFO -          Listening to:   tcp://172.21.2.201:43160
distributed.worker - INFO -          dashboard at:         172.21.2.201:41654
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-fh5p5esc
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.201:38867
distributed.worker - INFO -          Listening to:   tcp://172.21.2.201:38867
distributed.worker - INFO -          dashboard at:         172.21.2.201:41084
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ommwwkwj
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.216:38695
distributed.worker - INFO -          Listening to:   tcp://172.21.2.216:38695
distributed.worker - INFO -          dashboard at:         172.21.2.216:39918
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.216:42677
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://172.21.2.216:42677
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          dashboard at:         172.21.2.216:42232
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-faqlbe6l
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-g1dasfuz
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.192:42238
distributed.worker - INFO -          Listening to:   tcp://172.21.2.192:42238
distributed.worker - INFO -          dashboard at:         172.21.2.192:33991
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.192:39316
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -          Listening to:   tcp://172.21.2.192:39316
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-l_pnw12m
distributed.worker - INFO -          dashboard at:         172.21.2.192:34934
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ngivho0r
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.252:42528
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.252:41742
distributed.worker - INFO -          Listening to:   tcp://172.21.2.252:41742
distributed.worker - INFO -          dashboard at:         172.21.2.252:46753
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          Listening to:   tcp://172.21.2.252:42528
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -          dashboard at:         172.21.2.252:42667
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5f0gjbku
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ygdh2s20
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.180:40689
distributed.worker - INFO -          Listening to:   tcp://172.21.2.180:40689
distributed.worker - INFO -          dashboard at:         172.21.2.180:46414
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.180:39140
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://172.21.2.180:39140
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          dashboard at:         172.21.2.180:42701
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-jae9a6t2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nwwunom7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.214:40538
distributed.worker - INFO -          Listening to:   tcp://172.21.2.214:40538
distributed.worker - INFO -          dashboard at:         172.21.2.214:43884
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.214:36882
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-o2judjij
distributed.worker - INFO -          Listening to:   tcp://172.21.2.214:36882
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.21.2.214:46038
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-sqiod8v1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.233:41953
distributed.worker - INFO -          Listening to:   tcp://172.21.2.233:41953
distributed.worker - INFO -          dashboard at:         172.21.2.233:33176
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-vi5iw9nx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.233:42966
distributed.worker - INFO -          Listening to:   tcp://172.21.2.233:42966
distributed.worker - INFO -          dashboard at:         172.21.2.233:45945
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nzj2ii31
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.165:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
slurmstepd-irene1287: error: *** STEP 8468057.1 ON irene1287 CANCELLED AT 2023-02-22T09:08:46 ***
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.233:33572'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.180:37808'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.178:38333'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.171:39359'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.193:36923'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.201:44474'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.239:39444'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.212:37283'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.213:34592'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.192:36373'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.172:32898'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.211:43103'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.216:42938'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.214:44444'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.210:38972'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.233:44085'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.180:37128'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.178:40918'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.171:36583'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.193:40259'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.201:38866'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.239:43613'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.212:40589'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.213:45241'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.192:39719'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.172:46754'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.211:46536'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.216:45340'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.214:38689'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.210:36097'
distributed.worker - INFO - Stopping worker at tcp://172.21.2.178:44423
distributed.worker - INFO - Stopping worker at tcp://172.21.2.178:42035
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.252:35005'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.252:32921'
distributed.worker - INFO - Stopping worker at tcp://172.21.2.180:40689
distributed.worker - INFO - Stopping worker at tcp://172.21.2.180:39140
distributed.worker - INFO - Stopping worker at tcp://172.21.2.239:40928
distributed.worker - INFO - Stopping worker at tcp://172.21.2.239:35949
distributed.worker - INFO - Stopping worker at tcp://172.21.2.171:39372
distributed.worker - INFO - Stopping worker at tcp://172.21.2.171:39868
distributed.worker - INFO - Stopping worker at tcp://172.21.2.201:43160
distributed.worker - INFO - Stopping worker at tcp://172.21.2.201:38867
distributed.worker - INFO - Stopping worker at tcp://172.21.2.193:35830
distributed.worker - INFO - Stopping worker at tcp://172.21.2.193:45551
distributed.worker - INFO - Stopping worker at tcp://172.21.2.213:42503
distributed.worker - INFO - Stopping worker at tcp://172.21.2.172:42279
distributed.worker - INFO - Stopping worker at tcp://172.21.2.213:41273
distributed.worker - INFO - Stopping worker at tcp://172.21.2.172:36181
distributed.worker - INFO - Stopping worker at tcp://172.21.2.216:38695
distributed.worker - INFO - Stopping worker at tcp://172.21.2.216:42677
distributed.worker - INFO - Stopping worker at tcp://172.21.2.192:39316
distributed.worker - INFO - Stopping worker at tcp://172.21.2.210:33593
distributed.worker - INFO - Stopping worker at tcp://172.21.2.192:42238
distributed.worker - INFO - Stopping worker at tcp://172.21.2.210:36437
distributed.worker - INFO - Stopping worker at tcp://172.21.2.212:38490
distributed.worker - INFO - Stopping worker at tcp://172.21.2.212:46110
distributed.worker - INFO - Stopping worker at tcp://172.21.2.211:46026
distributed.worker - INFO - Stopping worker at tcp://172.21.2.211:46661
distributed.worker - INFO - Stopping worker at tcp://172.21.2.233:41953
distributed.worker - INFO - Stopping worker at tcp://172.21.2.233:42966
distributed.worker - INFO - Stopping worker at tcp://172.21.2.214:40538
distributed.worker - INFO - Stopping worker at tcp://172.21.2.214:36882
distributed.worker - INFO - Stopping worker at tcp://172.21.2.252:42528
distributed.worker - INFO - Stopping worker at tcp://172.21.2.252:41742
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=71586 parent=71479 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97394 parent=97289 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=51041 parent=50941 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=85999 parent=85901 started daemon>
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=82713 parent=82608 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=85998 parent=85900 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=82712 parent=82607 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97396 parent=97288 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=96047 parent=95946 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=96046 parent=95945 started daemon>
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=23195 parent=23091 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
Traceback (most recent call last):
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=70744 parent=70646 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=71585 parent=71480 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=29434 parent=29333 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=70743 parent=70645 started daemon>
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=92130 parent=92026 started daemon>
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=49038 parent=48932 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=49039 parent=48933 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=51042 parent=50942 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=22908 parent=22808 started daemon>
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=22416 parent=22312 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=92129 parent=92025 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32625 parent=32526 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=22907 parent=22809 started daemon>
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=28577 parent=28477 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=28576 parent=28478 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=29433 parent=29334 started daemon>
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32624 parent=32525 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=22417 parent=22311 started daemon>
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=29891 parent=29791 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=29890 parent=29790 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=23196 parent=23090 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Traceback (most recent call last):
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x5014c0)

Current thread 0x00002b142cee9b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x11b74c0)

Current thread 0x00002ab81057fb80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0xa434c0)

Current thread 0x00002ba9ce1f3b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x20184c0)

Current thread 0x00002b5c3b1c3b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x14004c0)

Current thread 0x00002b44f5aeeb80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x1b224c0)

Current thread 0x00002b55d1aabb80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x15a84c0)

Current thread 0x00002afe1c1bab80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0xf104c0)

Current thread 0x00002b1126961b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x1d444c0)

Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x12854c0)

Current thread 0x00002b64b7a83b80 (most recent call first):
<no Python frame>
Current thread 0x00002b42161a3b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x1ab04c0)

Current thread 0x00002b0c4de7db80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x6fa4c0)

Current thread 0x00002afe5e485b80 (most recent call first):
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x22cc4c0)

Current thread 0x00002b964cfc0b80 (most recent call first):
<no Python frame>
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x4e94c0)

Current thread 0x00002ae595dbdb80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x16bc4c0)

Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0xe784c0)

Current thread 0x00002af1f103ab80 (most recent call first):
<no Python frame>
Current thread 0x00002b972f1d7b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x47c4c0)

Current thread 0x00002b83d4b18b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x43a4c0)

Current thread 0x00002ab853352b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x14864c0)

Current thread 0x00002ab76a07fb80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x8c04c0)

Current thread 0x00002b49de902b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0xde54c0)

Current thread 0x00002b281c2c5b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x17ea4c0)

Current thread 0x00002afb5d2abb80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x1daf4c0)

Current thread 0x00002af837b2ab80 (most recent call first):
<no Python frame>
srun: error: irene1328: tasks 18-19: Aborted (core dumped)
srun: error: irene1288: tasks 2-3: Aborted (core dumped)
srun: error: irene1296: tasks 6-7: Aborted (core dumped)
srun: error: irene1368: tasks 30-31: Aborted (core dumped)
srun: error: irene1287: tasks 0-1: Aborted (core dumped)
srun: error: irene1329: tasks 20-21: Aborted (core dumped)
srun: error: irene1294: tasks 4-5: Aborted (core dumped)
srun: error: irene1309: tasks 10-11: Aborted (core dumped)
srun: error: irene1327: tasks 16-17: Aborted (core dumped)
srun: error: irene1317: task 13: Aborted (core dumped)
srun: error: irene1349: task 27: Aborted (core dumped)
srun: error: irene1355: task 28: Aborted (core dumped)
srun: error: irene1330: task 22: Aborted (core dumped)
srun: error: irene1332: task 24: Aborted (core dumped)
