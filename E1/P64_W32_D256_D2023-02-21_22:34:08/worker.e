distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.153:34978'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.153:37923'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.7.122:37467'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.7.122:44898'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.145:37073'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.159:35726'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.10.214:34940'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.145:42734'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.142:40443'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.151:46772'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.159:33507'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.10.169:35042'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.151:46050'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.10.169:43542'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.181:45815'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.7.131:35311'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.7.134:46161'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.7.131:40842'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.181:41674'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.10.214:39487'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.149:39777'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.155:43657'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.144:39102'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.7.135:44404'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.7.135:44671'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.144:37329'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.142:46079'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.7.134:34861'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.149:36457'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.155:42304'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.141:33751'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.11.141:37987'
distributed.worker - INFO -       Start worker at:   tcp://172.21.7.131:40814
distributed.worker - INFO -          Listening to:   tcp://172.21.7.131:40814
distributed.worker - INFO -       Start worker at:   tcp://172.21.7.131:33565
distributed.worker - INFO -          Listening to:   tcp://172.21.7.131:33565
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.142:45245
distributed.worker - INFO -          Listening to:  tcp://172.21.11.142:45245
distributed.worker - INFO -          dashboard at:        172.21.11.142:46610
distributed.worker - INFO -          dashboard at:         172.21.7.131:42737
distributed.worker - INFO -          dashboard at:         172.21.7.131:39501
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO -       Start worker at:  tcp://172.21.10.214:42282
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.142:45602
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          Listening to:  tcp://172.21.11.142:45602
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-xvhtvktp
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -          dashboard at:        172.21.11.142:40903
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-zshssjxn
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0yy944d4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-r8q2f48h
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.151:33875
distributed.worker - INFO -          Listening to:  tcp://172.21.11.151:33875
distributed.worker - INFO -          dashboard at:        172.21.11.151:35156
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO -       Start worker at:  tcp://172.21.10.214:41312
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.151:45404
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          Listening to:  tcp://172.21.11.151:45404
distributed.worker - INFO -          Listening to:  tcp://172.21.10.214:41312
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -          dashboard at:        172.21.11.151:37169
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:        172.21.10.214:35710
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ocpgqj0e
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-q7pdf51u
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ajvr555z
distributed.worker - INFO -          Listening to:  tcp://172.21.10.214:42282
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.144:40975
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:        172.21.10.214:33753
distributed.worker - INFO -          Listening to:  tcp://172.21.11.144:40975
distributed.worker - INFO -          dashboard at:        172.21.11.144:35382
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.144:33520
distributed.worker - INFO -          Listening to:  tcp://172.21.11.144:33520
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO -          dashboard at:        172.21.11.144:39786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_5i2x5ko
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_xydq8j5
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-r6tz17a6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.21.10.169:39003
distributed.worker - INFO -          Listening to:  tcp://172.21.10.169:39003
distributed.worker - INFO -          dashboard at:        172.21.10.169:42098
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.21.10.169:33527
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          Listening to:  tcp://172.21.10.169:33527
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -          dashboard at:        172.21.10.169:35688
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-oarqtp2d
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-bc5hnu8x
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.149:38249
distributed.worker - INFO -          Listening to:  tcp://172.21.11.149:38249
distributed.worker - INFO -          dashboard at:        172.21.11.149:40328
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.149:38195
distributed.worker - INFO -          Listening to:  tcp://172.21.11.149:38195
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-r6m0q5ps
distributed.worker - INFO -          dashboard at:        172.21.11.149:36570
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-askmtws4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.181:43444
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.181:36711
distributed.worker - INFO -          Listening to:  tcp://172.21.11.181:36711
distributed.worker - INFO -          dashboard at:        172.21.11.181:45690
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO -          Listening to:  tcp://172.21.11.181:43444
distributed.worker - INFO -          dashboard at:        172.21.11.181:39919
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_vyfl9ns
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-hzqjfwgu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.159:41812
distributed.worker - INFO -          Listening to:  tcp://172.21.11.159:41812
distributed.worker - INFO -          dashboard at:        172.21.11.159:42825
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.159:39081
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          Listening to:  tcp://172.21.11.159:39081
distributed.worker - INFO -          dashboard at:        172.21.11.159:37965
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8wjte6ny
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ze43f0tz
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.153:39637
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:  tcp://172.21.11.153:39637
distributed.worker - INFO -          dashboard at:        172.21.11.153:39984
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.153:39878
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          Listening to:  tcp://172.21.11.153:39878
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-g_e0ywcf
distributed.worker - INFO -          dashboard at:        172.21.11.153:40230
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-lpgopg_r
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.7.122:44086
distributed.worker - INFO -          Listening to:   tcp://172.21.7.122:44086
distributed.worker - INFO -          dashboard at:         172.21.7.122:34509
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO -       Start worker at:   tcp://172.21.7.135:41532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -          Listening to:   tcp://172.21.7.135:41532
distributed.worker - INFO -          dashboard at:         172.21.7.135:37590
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-f9o15y1w
distributed.worker - INFO -       Start worker at:   tcp://172.21.7.135:46213
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://172.21.7.135:46213
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          dashboard at:         172.21.7.135:38379
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-icj5i398
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-sg8xt0rh
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.7.122:39674
distributed.worker - INFO -          Listening to:   tcp://172.21.7.122:39674
distributed.worker - INFO -          dashboard at:         172.21.7.122:37911
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-w540a20_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://172.21.7.134:37602
distributed.worker - INFO -          Listening to:   tcp://172.21.7.134:37602
distributed.worker - INFO -          dashboard at:         172.21.7.134:45317
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Start worker at:   tcp://172.21.7.134:45566
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-tsfexx5a
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.155:42485
distributed.worker - INFO -          Listening to:   tcp://172.21.7.134:45566
distributed.worker - INFO -          dashboard at:         172.21.7.134:33057
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qgkckfwl
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.145:35735
distributed.worker - INFO -          Listening to:  tcp://172.21.11.145:35735
distributed.worker - INFO -          Listening to:  tcp://172.21.11.155:42485
distributed.worker - INFO -          dashboard at:        172.21.11.155:38106
distributed.worker - INFO -          dashboard at:        172.21.11.145:44529
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.145:33499
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:  tcp://172.21.11.145:33499
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          dashboard at:        172.21.11.145:42275
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-m1ip2i0e
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-y24f7xg9
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-zb_dq3h5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.155:41949
distributed.worker - INFO -          Listening to:  tcp://172.21.11.155:41949
distributed.worker - INFO -          dashboard at:        172.21.11.155:38074
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_bn3srdl
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.141:38884
distributed.worker - INFO -          Listening to:  tcp://172.21.11.141:38884
distributed.worker - INFO -          dashboard at:        172.21.11.141:33953
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO -       Start worker at:  tcp://172.21.11.141:33538
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-o3oidebz
distributed.worker - INFO -          Listening to:  tcp://172.21.11.141:33538
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:        172.21.11.141:43884
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-flnetrcm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.7.109:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
slurmstepd-irene2043: error: *** STEP 8466249.1 ON irene2043 CANCELLED AT 2023-02-22T04:49:53 ***
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.151:46772'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.10.169:35042'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.10.214:39487'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.142:40443'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.151:46050'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.10.169:43542'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.10.214:34940'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.142:46079'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.7.131:40842'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.7.131:35311'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.144:37329'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.141:33751'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.141:37987'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.144:39102'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.145:37073'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.145:42734'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.7.134:46161'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.7.134:34861'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.7.122:37467'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.7.122:44898'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.153:37923'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.153:34978'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.149:39777'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.worker - INFO - Stopping worker at tcp://172.21.11.145:33499
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.181:41674'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.149:36457'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.181:45815'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.7.135:44404'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.7.135:44671'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.155:43657'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.159:35726'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.155:42304'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.11.159:33507'
distributed.worker - INFO - Stopping worker at tcp://172.21.11.153:39637
distributed.worker - INFO - Stopping worker at tcp://172.21.11.145:35735
distributed.worker - INFO - Stopping worker at tcp://172.21.11.153:39878
distributed.worker - INFO - Stopping worker at tcp://172.21.10.169:33527
distributed.worker - INFO - Stopping worker at tcp://172.21.10.169:39003
distributed.worker - INFO - Stopping worker at tcp://172.21.11.151:45404
distributed.worker - INFO - Stopping worker at tcp://172.21.11.151:33875
distributed.worker - INFO - Stopping worker at tcp://172.21.11.141:33538
distributed.worker - INFO - Stopping worker at tcp://172.21.11.141:38884
distributed.worker - INFO - Stopping worker at tcp://172.21.11.159:39081
distributed.worker - INFO - Stopping worker at tcp://172.21.11.181:43444
distributed.worker - INFO - Stopping worker at tcp://172.21.11.159:41812
distributed.worker - INFO - Stopping worker at tcp://172.21.11.181:36711
distributed.worker - INFO - Stopping worker at tcp://172.21.11.155:41949
distributed.worker - INFO - Stopping worker at tcp://172.21.11.155:42485
distributed.worker - INFO - Stopping worker at tcp://172.21.11.142:45602
distributed.worker - INFO - Stopping worker at tcp://172.21.7.131:40814
distributed.worker - INFO - Stopping worker at tcp://172.21.11.142:45245
distributed.worker - INFO - Stopping worker at tcp://172.21.7.131:33565
distributed.worker - INFO - Stopping worker at tcp://172.21.11.144:33520
distributed.worker - INFO - Stopping worker at tcp://172.21.11.144:40975
distributed.worker - INFO - Stopping worker at tcp://172.21.11.149:38249
distributed.worker - INFO - Stopping worker at tcp://172.21.11.149:38195
distributed.worker - INFO - Stopping worker at tcp://172.21.7.122:44086
distributed.worker - INFO - Stopping worker at tcp://172.21.7.122:39674
distributed.worker - INFO - Stopping worker at tcp://172.21.10.214:41312
distributed.worker - INFO - Stopping worker at tcp://172.21.10.214:42282
distributed.worker - INFO - Stopping worker at tcp://172.21.7.134:37602
distributed.worker - INFO - Stopping worker at tcp://172.21.7.134:45566
distributed.worker - INFO - Stopping worker at tcp://172.21.7.135:46213
distributed.worker - INFO - Stopping worker at tcp://172.21.7.135:41532
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=50422 parent=50317 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=50423 parent=50316 started daemon>
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=94331 parent=94226 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=904 parent=795 started daemon>
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=6053 parent=5948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=94332 parent=94227 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=9297 parent=9194 started daemon>
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=95984 parent=95880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47809 parent=47704 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=905 parent=794 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=84316 parent=84213 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=56388 parent=56285 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=6052 parent=5949 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36871 parent=36766 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=84315 parent=84212 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=9298 parent=9195 started daemon>
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
Traceback (most recent call last):
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=85369 parent=85264 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47808 parent=47703 started daemon>
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36872 parent=36767 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=95985 parent=95879 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=15835 parent=15737 started daemon>
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=56389 parent=56286 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=91464 parent=91361 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=85368 parent=85265 started daemon>
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=7169 parent=7064 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=7170 parent=7063 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=15836 parent=15736 started daemon>
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=91465 parent=91360 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=87962 parent=87857 started daemon>
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=87963 parent=87858 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=87191 parent=87086 started daemon>
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=87192 parent=87087 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x5684c0)

Current thread 0x00002b0724516b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x11954c0)

Current thread 0x00002ae611995b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x186e4c0)

Current thread 0x00002afa6a7c6b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x14214c0)

Current thread 0x00002b0b1b13db80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x4e64c0)

Current thread 0x00002b6c983aeb80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x1b114c0)

Current thread 0x00002b8ffd7c4b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0xa384c0)

Current thread 0x00002b7b096a7b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x4674c0)

Current thread 0x00002ad002351b80 (most recent call first):
<no Python frame>
srun: error: irene2389: task 9: Aborted (core dumped)
srun: error: irene2618: task 19: Aborted (core dumped)
srun: error: irene2628: task 27: Aborted (core dumped)
srun: error: irene2622: task 20: Aborted (core dumped)
srun: error: irene2043: task 1: Aborted (core dumped)
srun: error: irene2624: task 22: Aborted (core dumped)
srun: error: irene2052: task 2: Aborted (core dumped)
srun: error: irene2626: task 25: Aborted (core dumped)
