distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.3.94:37178'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.179:44557'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.3.104:36722'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.3.9:44499'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.3.87:39049'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.3.131:46473'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.3.126:32899'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.2.179:36333'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.3.104:39172'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.3.102:33832'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.3.102:36110'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.3.9:34413'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.3.87:44647'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.3.94:37636'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.3.131:38614'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.3.126:45115'
distributed.worker - INFO -       Start worker at:   tcp://172.21.3.102:43936
distributed.worker - INFO -          Listening to:   tcp://172.21.3.102:43936
distributed.worker - INFO -       Start worker at:   tcp://172.21.3.104:37018
distributed.worker - INFO -          Listening to:   tcp://172.21.3.104:37018
distributed.worker - INFO -       Start worker at:     tcp://172.21.3.9:41683
distributed.worker - INFO -          Listening to:     tcp://172.21.3.9:41683
distributed.worker - INFO -       Start worker at:   tcp://172.21.3.126:39985
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.179:34573
distributed.worker - INFO -          Listening to:   tcp://172.21.2.179:34573
distributed.worker - INFO -          dashboard at:         172.21.2.179:38958
distributed.worker - INFO -          dashboard at:         172.21.3.102:33587
distributed.worker - INFO -          dashboard at:         172.21.3.104:42521
distributed.worker - INFO -          dashboard at:           172.21.3.9:38852
distributed.worker - INFO -       Start worker at:    tcp://172.21.3.87:36040
distributed.worker - INFO -          Listening to:    tcp://172.21.3.87:36040
distributed.worker - INFO -       Start worker at:    tcp://172.21.3.94:36511
distributed.worker - INFO -          Listening to:    tcp://172.21.3.94:36511
distributed.worker - INFO -          dashboard at:          172.21.3.94:36095
distributed.worker - INFO -       Start worker at:   tcp://172.21.3.131:44871
distributed.worker - INFO -          Listening to:   tcp://172.21.3.126:39985
distributed.worker - INFO -       Start worker at:   tcp://172.21.2.179:33916
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:          172.21.3.87:34127
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO -          Listening to:   tcp://172.21.3.131:44871
distributed.worker - INFO -          dashboard at:         172.21.3.126:38456
distributed.worker - INFO -          Listening to:   tcp://172.21.2.179:33916
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Start worker at:    tcp://172.21.3.87:36397
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.21.3.131:33853
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -          Listening to:    tcp://172.21.3.87:36397
distributed.worker - INFO -       Start worker at:    tcp://172.21.3.94:41513
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.21.2.179:35202
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-x07hqm4l
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-uzjuscv5
distributed.worker - INFO -          dashboard at:          172.21.3.87:43823
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3uzn51gx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO -          Listening to:    tcp://172.21.3.94:41513
distributed.worker - INFO -       Start worker at:   tcp://172.21.3.131:46756
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO -       Start worker at:   tcp://172.21.3.102:43860
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://172.21.3.9:38848
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-duxy1hns
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -          Listening to:   tcp://172.21.3.102:43860
distributed.worker - INFO -       Start worker at:   tcp://172.21.3.104:42918
distributed.worker - INFO -          Listening to:     tcp://172.21.3.9:38848
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-o8dm3bvb
distributed.worker - INFO -          Listening to:   tcp://172.21.3.131:46756
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.21.3.102:36500
distributed.worker - INFO -          Listening to:   tcp://172.21.3.104:42918
distributed.worker - INFO -          dashboard at:           172.21.3.9:42164
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:          172.21.3.94:39082
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Start worker at:   tcp://172.21.3.126:34952
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO -          dashboard at:         172.21.3.104:33248
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-h69_h657
distributed.worker - INFO -          Listening to:   tcp://172.21.3.126:34952
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.21.3.131:43391
distributed.worker - INFO -          dashboard at:         172.21.3.126:43240
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-w5q28swg
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-y35fsnyw
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ji3om_dl
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - Waiting to connect to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-avqx06nk
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-l_1xn4hr
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-p_6she6r
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-03dz335h
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-21kmizuh
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qvodnyfm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-202v0_3r
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:    tcp://172.21.2.166:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
slurmstepd-irene1295: error: *** STEP 8478938.1 ON irene1295 CANCELLED AT 2023-02-23T05:52:38 ***
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.3.104:36722'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.3.104:39172'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.3.87:39049'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.3.87:44647'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.3.126:45115'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.3.126:32899'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.179:44557'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.2.179:36333'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.3.102:33832'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.3.102:36110'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.3.131:46473'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.3.131:38614'
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.3.9:34413'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.3.9:44499'
distributed.worker - INFO - Stopping worker at tcp://172.21.2.179:33916
distributed.worker - INFO - Stopping worker at tcp://172.21.3.87:36040
distributed.worker - INFO - Stopping worker at tcp://172.21.2.179:34573
distributed.worker - INFO - Stopping worker at tcp://172.21.3.87:36397
distributed.worker - INFO - Stopping worker at tcp://172.21.3.126:34952
distributed.worker - INFO - Stopping worker at tcp://172.21.3.126:39985
distributed.worker - INFO - Stopping worker at tcp://172.21.3.102:43860
distributed.worker - INFO - Stopping worker at tcp://172.21.3.102:43936
distributed.worker - INFO - Stopping worker at tcp://172.21.3.104:37018
distributed.worker - INFO - Stopping worker at tcp://172.21.3.104:42918
distributed.worker - INFO - Stopping worker at tcp://172.21.3.131:44871
distributed.worker - INFO - Stopping worker at tcp://172.21.3.131:46756
distributed.worker - INFO - Stopping worker at tcp://172.21.3.9:41683
distributed.worker - INFO - Stopping worker at tcp://172.21.3.9:38848
distributed.dask_worker - INFO - Exiting on signal 15
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.3.94:37178'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.3.94:37636'
distributed.worker - INFO - Stopping worker at tcp://172.21.3.94:41513
distributed.worker - INFO - Stopping worker at tcp://172.21.3.94:36511
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=20358 parent=20239 started daemon>
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=20357 parent=20240 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=19132 parent=19014 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=19133 parent=19013 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=88044 parent=87919 started daemon>
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=21799 parent=21680 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=88043 parent=87920 started daemon>
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54446 parent=54329 started daemon>
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=89908 parent=89778 started daemon>
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=89907 parent=89779 started daemon>
distributed.dask_worker - INFO - End worker
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=96981 parent=96856 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54447 parent=54328 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=96980 parent=96855 started daemon>
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=21800 parent=21679 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=40091 parent=39975 started daemon>
distributed.nanny - WARNING - Worker process still alive after 1 seconds, killing
distributed.dask_worker - INFO - End worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=40092 parent=39976 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x14344c0)

Current thread 0x00002b3fdd891b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x1e724c0)

Current thread 0x00002adedcb29b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x1ed74c0)

Current thread 0x00002b8c107e7b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x1a364c0)

Current thread 0x00002b09771e6b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x6bd4c0)

Current thread 0x00002b11dbbd8b80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x1d744c0)

Current thread 0x00002ad3280bab80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x1d8d4c0)

Current thread 0x00002adf7d03ab80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x15e74c0)

Current thread 0x00002af8d999fb80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x19784c0)

Current thread 0x00002b58b83deb80 (most recent call first):
<no Python frame>
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x6a64c0)

Current thread 0x00002b2b483edb80 (most recent call first):
<no Python frame>
srun: error: irene1295: tasks 0-1: Aborted (core dumped)
srun: error: irene1473: tasks 10-11: Aborted (core dumped)
srun: error: irene1463: tasks 6-7: Aborted (core dumped)
srun: error: irene1378: task 3: Aborted (core dumped)
srun: error: irene1500: task 14: Aborted (core dumped)
srun: error: irene1471: task 8: Aborted (core dumped)
srun: error: irene1495: task 13: Aborted (core dumped)
