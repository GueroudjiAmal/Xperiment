distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.184:38858'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.184:45780'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.57:46273'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.57:37485'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.198:35850'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.55:34132'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.55:33309'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.198:35222'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.169:33014'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.169:41105'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.86:42139'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.60:33021'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.86:33821'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.60:39271'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.87:44556'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.190:43536'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.87:42188'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.190:33582'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.191:35396'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.191:42466'
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.55:38407
distributed.worker - INFO -          Listening to:    tcp://172.21.5.55:38407
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.57:36980
distributed.worker - INFO -          dashboard at:          172.21.5.55:41534
distributed.worker - INFO -          Listening to:    tcp://172.21.5.57:36980
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.57:41143
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.86:46213
distributed.worker - INFO -       Start worker at:   tcp://172.21.5.169:36092
distributed.worker - INFO -          Listening to:   tcp://172.21.5.169:36092
distributed.worker - INFO -          dashboard at:          172.21.5.57:39066
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.60:42568
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -          dashboard at:         172.21.5.169:33520
distributed.worker - INFO -          Listening to:    tcp://172.21.5.57:41143
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.184:37202
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-dlsb073t
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.190:45729
distributed.worker - INFO -          Listening to:    tcp://172.21.5.86:46213
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.87:37831
distributed.worker - INFO -          Listening to:    tcp://172.21.5.87:37831
distributed.worker - INFO -          dashboard at:          172.21.5.87:46092
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.198:46098
distributed.worker - INFO -          Listening to:   tcp://172.21.6.198:46098
distributed.worker - INFO -          Listening to:    tcp://172.21.5.60:42568
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.55:37508
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:          172.21.5.57:38929
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.87:40173
distributed.worker - INFO -          Listening to:   tcp://172.21.6.184:37202
distributed.worker - INFO -          dashboard at:          172.21.5.60:45701
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.191:43191
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:          172.21.5.86:34801
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:    tcp://172.21.5.87:40173
distributed.worker - INFO -          dashboard at:         172.21.6.184:41600
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -          Listening to:    tcp://172.21.5.55:37508
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.86:44786
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -          dashboard at:         172.21.6.198:39013
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.60:38146
distributed.worker - INFO -          dashboard at:          172.21.5.55:36423
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -       Start worker at:   tcp://172.21.5.169:44633
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          dashboard at:          172.21.5.87:40915
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -          Listening to:    tcp://172.21.5.60:38146
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -          Listening to:   tcp://172.21.6.190:45729
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-73faeae1
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:          172.21.5.60:42950
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.21.6.190:42839
distributed.worker - INFO -          Listening to:    tcp://172.21.5.86:44786
distributed.worker - INFO -          Listening to:   tcp://172.21.5.169:44633
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-tkwnomxk
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.198:45174
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          dashboard at:         172.21.5.169:40689
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ttto67_6
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -          Listening to:   tcp://172.21.6.191:43191
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:          172.21.5.86:45470
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.184:35773
distributed.worker - INFO -          Listening to:   tcp://172.21.6.198:45174
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          dashboard at:         172.21.6.191:36861
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-aaky5xh5
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.190:35480
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.21.6.198:43627
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          Listening to:   tcp://172.21.6.184:35773
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://172.21.6.190:35480
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-hjbevbc3
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-z5bhsmb2
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-kskmgmru
distributed.worker - INFO -          dashboard at:         172.21.6.184:46568
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-sinjjw30
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-m5dkjji4
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-z9adsj_y
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-90phl8nt
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.191:46303
distributed.worker - INFO -          dashboard at:         172.21.6.190:44550
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5yj7kspg
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ysgkhhb4
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-wq_ow6bg
distributed.worker - INFO -          Listening to:   tcp://172.21.6.191:46303
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-hehwdk54
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mmy5aute
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nkotxto7
distributed.worker - INFO -          dashboard at:         172.21.6.191:42703
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nid79rua
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-q0eq1xd_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.65:44632'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.65:34137'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.52:43121'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.52:45762'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.187:38117'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.187:42855'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.63:44439'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.63:33903'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.51:34506'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.51:38205'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.170:35730'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.170:42335'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.50:41344'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.58:44559'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.50:35571'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.58:44226'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.189:38253'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.195:34215'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.189:34847'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.195:36097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.90:46304'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.64:41700'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.90:45909'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.64:35958'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.54:33914'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.54:44064'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.59:37396'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.59:34162'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.56:42428'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.53:42369'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.56:41159'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.53:33176'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.61:43575'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.186:44769'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.61:40578'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.186:33503'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.62:40447'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.62:42087'
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.64:44872
distributed.worker - INFO -          Listening to:    tcp://172.21.5.64:44872
distributed.worker - INFO -          dashboard at:          172.21.5.64:45979
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-o79afr25
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.64:36145
distributed.worker - INFO -          Listening to:    tcp://172.21.5.64:36145
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:          172.21.5.64:38988
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1qg_pypv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.61:36659
distributed.worker - INFO -          Listening to:    tcp://172.21.5.61:36659
distributed.worker - INFO -          dashboard at:          172.21.5.61:45099
distributed.worker - INFO -       Start worker at:   tcp://172.21.5.170:45127
distributed.worker - INFO -          Listening to:   tcp://172.21.5.170:45127
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.58:36190
distributed.worker - INFO -          Listening to:    tcp://172.21.5.58:36190
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.62:42419
distributed.worker - INFO -          Listening to:    tcp://172.21.5.62:42419
distributed.worker - INFO -          dashboard at:         172.21.5.170:34529
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.52:41819
distributed.worker - INFO -          Listening to:    tcp://172.21.5.52:41819
distributed.worker - INFO -          dashboard at:          172.21.5.58:40369
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.189:37725
distributed.worker - INFO -          Listening to:   tcp://172.21.6.189:37725
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.59:43819
distributed.worker - INFO -          Listening to:    tcp://172.21.5.59:43819
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.187:37997
distributed.worker - INFO -          Listening to:   tcp://172.21.6.187:37997
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.195:35472
distributed.worker - INFO -          Listening to:   tcp://172.21.6.195:35472
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.186:38755
distributed.worker - INFO -          Listening to:   tcp://172.21.6.186:38755
distributed.worker - INFO -          dashboard at:          172.21.5.62:42608
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.50:41831
distributed.worker - INFO -          Listening to:    tcp://172.21.5.50:41831
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.54:43826
distributed.worker - INFO -          Listening to:    tcp://172.21.5.54:43826
distributed.worker - INFO -          dashboard at:          172.21.5.54:45904
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.63:41820
distributed.worker - INFO -          Listening to:    tcp://172.21.5.63:41820
distributed.worker - INFO -          dashboard at:          172.21.5.63:34368
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.51:45850
distributed.worker - INFO -          Listening to:    tcp://172.21.5.51:45850
distributed.worker - INFO -          dashboard at:          172.21.5.52:39740
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.56:39505
distributed.worker - INFO -          Listening to:    tcp://172.21.5.56:39505
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.90:33276
distributed.worker - INFO -          Listening to:    tcp://172.21.5.90:33276
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.53:42069
distributed.worker - INFO -          Listening to:    tcp://172.21.5.53:42069
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.65:35628
distributed.worker - INFO -          Listening to:    tcp://172.21.5.65:35628
distributed.worker - INFO -          dashboard at:          172.21.5.65:38247
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -          dashboard at:         172.21.6.189:40719
distributed.worker - INFO -          dashboard at:          172.21.5.59:38375
distributed.worker - INFO -          dashboard at:         172.21.6.187:46608
distributed.worker - INFO -          dashboard at:         172.21.6.195:46258
distributed.worker - INFO -          dashboard at:         172.21.6.186:40653
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:          172.21.5.50:45837
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -          dashboard at:          172.21.5.51:45014
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:          172.21.5.56:39894
distributed.worker - INFO -          dashboard at:          172.21.5.90:37239
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -          dashboard at:          172.21.5.53:41040
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-h360sb39
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.50:42080
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.51:42576
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.90:40601
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.58:38836
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.62:36413
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1d5w36_b
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.61:34858
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.63:38904
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-jv_nun45
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-dc70dts7
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-bj8gexio
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-zk0no8vg
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nnx0m7sf
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.54:38329
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:    tcp://172.21.5.61:34858
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-19ng0fyi
distributed.worker - INFO -          Listening to:    tcp://172.21.5.51:42576
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.56:37820
distributed.worker - INFO -          Listening to:    tcp://172.21.5.90:40601
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-7pxbcph1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-65k0ob2_
distributed.worker - INFO -          Listening to:    tcp://172.21.5.58:38836
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nsp2vk5d
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-evqfqnu4
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.186:42634
distributed.worker - INFO -          Listening to:    tcp://172.21.5.62:36413
distributed.worker - INFO -          Listening to:    tcp://172.21.5.50:42080
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-tk4edjr_
distributed.worker - INFO -       Start worker at:   tcp://172.21.5.170:43215
distributed.worker - INFO -          dashboard at:          172.21.5.61:36517
distributed.worker - INFO -          Listening to:    tcp://172.21.5.63:38904
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.52:40864
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-hzm2zo36
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.65:46295
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-xxcuwxv0
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.189:34917
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.59:39269
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.187:37358
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -          Listening to:    tcp://172.21.5.54:38329
distributed.worker - INFO -          Listening to:   tcp://172.21.5.170:43215
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -          dashboard at:          172.21.5.63:41504
distributed.worker - INFO -          dashboard at:          172.21.5.51:38593
distributed.worker - INFO -          Listening to:    tcp://172.21.5.52:40864
distributed.worker - INFO -          Listening to:    tcp://172.21.5.56:37820
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-id38esgy
distributed.worker - INFO -       Start worker at:    tcp://172.21.5.53:36325
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:          172.21.5.58:44676
distributed.worker - INFO -          Listening to:   tcp://172.21.6.189:34917
distributed.worker - INFO -          Listening to:    tcp://172.21.5.59:39269
distributed.worker - INFO -          Listening to:   tcp://172.21.6.187:37358
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.195:36840
distributed.worker - INFO -          Listening to:   tcp://172.21.6.186:42634
distributed.worker - INFO -          dashboard at:          172.21.5.62:35114
distributed.worker - INFO -          dashboard at:          172.21.5.50:46480
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.21.5.170:35472
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mqz2r2lo
distributed.worker - INFO -          dashboard at:          172.21.5.52:45974
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:          172.21.5.90:37834
distributed.worker - INFO -          Listening to:    tcp://172.21.5.53:36325
distributed.worker - INFO -          Listening to:    tcp://172.21.5.65:46295
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.21.6.189:43233
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.21.6.187:39828
distributed.worker - INFO -          Listening to:   tcp://172.21.6.195:36840
distributed.worker - INFO -          dashboard at:         172.21.6.186:40765
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-h3c1lnms
distributed.worker - INFO -          dashboard at:          172.21.5.54:42378
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -          dashboard at:          172.21.5.56:41894
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -          dashboard at:          172.21.5.53:46762
distributed.worker - INFO -          dashboard at:          172.21.5.65:43159
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -          dashboard at:          172.21.5.59:45506
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          dashboard at:         172.21.6.195:34740
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-d6ejbxvm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nfzf0zl9
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-no63rez4
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-kzksuaua
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-gnbv1rv2
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-y0lqwngq
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-m4d4pfel
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-egjsha84
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ojr18wav
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-oobs1w1t
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-tfjkviw7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-7d4cvsrf
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-dmniv9c0
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-43aba6d4
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4dwu6hwy
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ucr5nxx3
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-sbtzq9af
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-t48il6o8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.196:39203'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.197:42038'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.185:41149'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.185:46031'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.197:36711'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.196:45978'
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.196:33156
distributed.worker - INFO -          Listening to:   tcp://172.21.6.196:33156
distributed.worker - INFO -          dashboard at:         172.21.6.196:36805
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.196:46400
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -          Listening to:   tcp://172.21.6.196:46400
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-swm4vrfy
distributed.worker - INFO -          dashboard at:         172.21.6.196:40598
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-tweorgte
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.197:38133
distributed.worker - INFO -          Listening to:   tcp://172.21.6.197:38133
distributed.worker - INFO -          dashboard at:         172.21.6.197:32827
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.197:33148
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -          Listening to:   tcp://172.21.6.197:33148
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-bo6_mhzz
distributed.worker - INFO -          dashboard at:         172.21.6.197:33813
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-gavso2f1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.185:41331
distributed.worker - INFO -          Listening to:   tcp://172.21.6.185:41331
distributed.worker - INFO -          dashboard at:         172.21.6.185:38075
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-7wzzb26x
distributed.worker - INFO -       Start worker at:   tcp://172.21.6.185:37983
distributed.worker - INFO -          Listening to:   tcp://172.21.6.185:37983
distributed.worker - INFO -          dashboard at:         172.21.6.185:46006
distributed.worker - INFO - Waiting to connect to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         24
distributed.worker - INFO -                Memory:                 172.73 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-haby90du
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:     tcp://172.21.5.48:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Event loop was unresponsive in Worker for 259.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - ERROR - Worker stream died during communication: tcp://172.21.6.186:42634
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 2878, in gather_dep
    response = await get_data_from_worker(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 4143, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 4120, in _get_data
    comm = await rpc.connect(worker)
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 1081, in connect
    raise exc
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 1065, in connect
    comm = await fut
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/core.py", line 324, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://172.21.6.186:42634 after 30 s
distributed.worker - ERROR - Worker stream died during communication: tcp://172.21.5.169:44633
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 2878, in gather_dep
    response = await get_data_from_worker(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 4143, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 4120, in _get_data
    comm = await rpc.connect(worker)
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 1081, in connect
    raise exc
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 1065, in connect
    comm = await fut
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/core.py", line 324, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://172.21.5.169:44633 after 30 s
distributed.worker - ERROR - Worker stream died during communication: tcp://172.21.6.186:42634
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 2878, in gather_dep
    response = await get_data_from_worker(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 4143, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 4120, in _get_data
    comm = await rpc.connect(worker)
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 1081, in connect
    raise exc
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 1065, in connect
    comm = await fut
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/core.py", line 324, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://172.21.6.186:42634 after 30 s
distributed.core - INFO - Event loop was unresponsive in Worker for 56.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - ERROR - Worker stream died during communication: tcp://172.21.6.187:37997
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 2878, in gather_dep
    response = await get_data_from_worker(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 4143, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 4120, in _get_data
    comm = await rpc.connect(worker)
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 1081, in connect
    raise exc
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 1065, in connect
    comm = await fut
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/core.py", line 324, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://172.21.6.187:37997 after 30 s
distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 67.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 95.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection from tcp://172.21.5.57:59778 closed before handshake completed
distributed.worker - ERROR - Worker stream died during communication: tcp://172.21.6.189:34917
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 2878, in gather_dep
    response = await get_data_from_worker(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 4143, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 4120, in _get_data
    comm = await rpc.connect(worker)
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 1081, in connect
    raise exc
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 1065, in connect
    comm = await fut
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/core.py", line 324, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://172.21.6.189:34917 after 30 s
distributed.core - INFO - Event loop was unresponsive in Worker for 97.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 98.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 110.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 112.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 127.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection from tcp://172.21.5.59:54572 closed before handshake completed
distributed.comm.tcp - INFO - Connection from tcp://172.21.5.62:42442 closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 142.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 182.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 197.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 228.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection from tcp://172.21.5.57:33242 closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 255.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection from tcp://172.21.5.57:33578 closed before handshake completed
distributed.worker - ERROR - Worker stream died during communication: tcp://172.21.6.195:35472
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/._view/whcr3wyhzgorszy3rfxsphyebtvfpqzk/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 2878, in gather_dep
    response = await get_data_from_worker(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 4143, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 4120, in _get_data
    comm = await rpc.connect(worker)
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 1081, in connect
    raise exc
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 1065, in connect
    comm = await fut
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/core.py", line 324, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://172.21.6.195:35472 after 30 s
distributed.core - INFO - Event loop was unresponsive in Worker for 615.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection from tcp://172.21.5.63:35604 closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 870.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 931.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.21.5.50:42080
distributed.worker - INFO - Stopping worker at tcp://172.21.5.169:36092
distributed.worker - INFO - Stopping worker at tcp://172.21.5.50:41831
distributed.worker - INFO - Stopping worker at tcp://172.21.5.51:42576
distributed.worker - INFO - Stopping worker at tcp://172.21.5.169:44633
distributed.worker - INFO - Stopping worker at tcp://172.21.5.51:45850
distributed.worker - INFO - Stopping worker at tcp://172.21.5.170:43215
distributed.worker - INFO - Stopping worker at tcp://172.21.5.55:38407
distributed.worker - INFO - Stopping worker at tcp://172.21.5.170:45127
distributed.worker - INFO - Stopping worker at tcp://172.21.5.55:37508
distributed.worker - INFO - Stopping worker at tcp://172.21.5.52:40864
distributed.worker - INFO - Stopping worker at tcp://172.21.5.53:42069
distributed.worker - INFO - Stopping worker at tcp://172.21.5.54:43826
distributed.worker - INFO - Stopping worker at tcp://172.21.5.56:39505
distributed.worker - INFO - Stopping worker at tcp://172.21.5.57:36980
distributed.worker - INFO - Stopping worker at tcp://172.21.5.53:36325
distributed.worker - INFO - Stopping worker at tcp://172.21.5.52:41819
distributed.worker - INFO - Stopping worker at tcp://172.21.5.56:37820
distributed.worker - INFO - Stopping worker at tcp://172.21.5.57:41143
distributed.worker - INFO - Stopping worker at tcp://172.21.5.54:38329
distributed.worker - INFO - Stopping worker at tcp://172.21.5.59:39269
distributed.worker - INFO - Stopping worker at tcp://172.21.5.58:36190
distributed.worker - INFO - Stopping worker at tcp://172.21.5.59:43819
distributed.worker - INFO - Stopping worker at tcp://172.21.5.58:38836
distributed.worker - INFO - Stopping worker at tcp://172.21.5.60:38146
distributed.worker - INFO - Stopping worker at tcp://172.21.5.60:42568
distributed.worker - INFO - Stopping worker at tcp://172.21.5.62:36413
distributed.worker - INFO - Stopping worker at tcp://172.21.5.61:36659
distributed.worker - INFO - Stopping worker at tcp://172.21.5.62:42419
distributed.worker - INFO - Stopping worker at tcp://172.21.5.61:34858
distributed.worker - INFO - Stopping worker at tcp://172.21.5.64:36145
distributed.worker - INFO - Stopping worker at tcp://172.21.5.63:41820
distributed.worker - INFO - Stopping worker at tcp://172.21.5.63:38904
distributed.worker - INFO - Stopping worker at tcp://172.21.5.64:44872
distributed.worker - INFO - Stopping worker at tcp://172.21.5.86:44786
distributed.worker - INFO - Stopping worker at tcp://172.21.5.65:35628
distributed.worker - INFO - Stopping worker at tcp://172.21.5.86:46213
distributed.worker - INFO - Stopping worker at tcp://172.21.5.65:46295
distributed.worker - INFO - Stopping worker at tcp://172.21.5.87:40173
distributed.worker - INFO - Stopping worker at tcp://172.21.5.90:40601
distributed.worker - INFO - Stopping worker at tcp://172.21.5.90:33276
distributed.worker - INFO - Stopping worker at tcp://172.21.5.87:37831
distributed.worker - INFO - Stopping worker at tcp://172.21.6.186:38755
distributed.worker - INFO - Stopping worker at tcp://172.21.6.185:37983
distributed.worker - INFO - Stopping worker at tcp://172.21.6.186:42634
distributed.worker - INFO - Stopping worker at tcp://172.21.6.184:35773
distributed.worker - INFO - Stopping worker at tcp://172.21.6.187:37358
distributed.worker - INFO - Stopping worker at tcp://172.21.6.185:41331
distributed.worker - INFO - Stopping worker at tcp://172.21.6.184:37202
distributed.worker - INFO - Stopping worker at tcp://172.21.6.187:37997
distributed.worker - INFO - Stopping worker at tcp://172.21.6.190:45729
distributed.worker - INFO - Stopping worker at tcp://172.21.6.189:37725
distributed.worker - INFO - Stopping worker at tcp://172.21.6.195:35472
distributed.worker - INFO - Stopping worker at tcp://172.21.6.189:34917
distributed.worker - INFO - Stopping worker at tcp://172.21.6.195:36840
distributed.worker - INFO - Stopping worker at tcp://172.21.6.191:43191
distributed.worker - INFO - Stopping worker at tcp://172.21.6.190:35480
distributed.worker - INFO - Stopping worker at tcp://172.21.6.198:45174
distributed.worker - INFO - Stopping worker at tcp://172.21.6.198:46098
distributed.worker - INFO - Stopping worker at tcp://172.21.6.191:46303
distributed.worker - INFO - Stopping worker at tcp://172.21.6.197:33148
distributed.worker - INFO - Stopping worker at tcp://172.21.6.196:33156
distributed.worker - INFO - Stopping worker at tcp://172.21.6.196:46400
distributed.worker - INFO - Stopping worker at tcp://172.21.6.197:38133
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.55:34132'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.55:33309'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.51:34506'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.56:41159'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.51:38205'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.54:44064'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.53:33176'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.53:42369'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.52:43121'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.54:33914'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.170:42335'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.56:42428'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.52:45762'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.170:35730'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.58:44226'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.50:35571'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.58:44559'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.60:33021'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.60:39271'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.50:41344'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.59:37396'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.57:46273'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.57:37485'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.169:41105'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.169:33014'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.63:44439'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.63:33903'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.59:34162'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.62:40447'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.62:42087'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.61:40578'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.61:43575'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.65:34137'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.65:44632'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.64:35958'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.64:41700'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.90:45909'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.87:44556'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.86:33821'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.87:42188'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.86:42139'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.186:44769'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.186:33503'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.184:38858'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.185:46031'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.185:41149'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.184:45780'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.189:38253'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.198:35222'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.195:36097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.189:34847'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.187:38117'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.187:42855'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.198:35850'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.195:34215'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.196:39203'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.196:45978'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.191:42466'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.190:43536'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.191:35396'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.190:33582'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.197:42038'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.6.197:36711'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 896, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/core.py", line 671, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/tcp.py", line 221, in read
    convert_stream_closed_error(self, e)
distributed.nanny - INFO - Worker closed
  File "/ccc/work/cont003/gen2224/gen2224/spack/var/spack/environments/gysela-deisa-irene-skl-draft/.spack-env/view/lib/python3.9/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://172.21.6.197:60762 remote=tcp://172.21.5.48:8786>: Stream is closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.21.5.90:46304'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.185:46031'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.185:41149'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.63:44439'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.55:34132'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.54:44064'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.196:39203'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.197:42038'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.196:45978'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.197:36711'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.51:38205'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.60:39271'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.191:42466'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.55:33309'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.61:43575'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.64:35958'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.187:42855'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.53:33176'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.50:41344'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.90:45909'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.62:42087'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.86:33821'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.169:33014'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.57:46273'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.198:35222'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.59:37396'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.87:42188'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.170:35730'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.51:34506'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.65:34137'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.56:41159'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.190:43536'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.52:45762'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.191:35396'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.189:34847'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.195:36097'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.58:44226'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.61:40578'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.53:42369'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.184:45780'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.50:35571'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.54:33914'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.57:37485'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.62:40447'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.59:34162'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.86:42139'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.170:42335'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.187:38117'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.186:33503'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.87:44556'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.198:35850'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.52:43121'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.64:41700'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.65:44632'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.56:42428'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.190:33582'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.169:41105'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.189:38253'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.90:46304'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.195:34215'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.58:44559'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.63:33903'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.184:38858'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.6.186:44769'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://172.21.5.60:33021'
distributed.dask_worker - INFO - End worker
